{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Python` como lenguaje tiene las siguientes características:\n",
    "\n",
    "* Alto nivel\n",
    "* Intepretado\n",
    "* Orientado a objetos (pero en realidad multiparadigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de programa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mostrar las facilidades de comprensión de los programas en `python` observe lo siguiente:\n",
    "\n",
    "```python\n",
    "\n",
    "for line in open(”file.txt”):\n",
    "    for word in line.split():\n",
    "        if word.endswith(”ing”):\n",
    "            print word\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se puede leer línea por línea en inglés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones en python\n",
    "\n",
    "En términos básicos una _función_ es una manera de empaquetar código para su posterior reuso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repetir(texto, num_veces):\n",
    "    return texto*num_veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monty = \"Monty Python \"\n",
    "repetir(monty, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repetir(\"Hola Puno \", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También existen las funciones anónimas o funciones _lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cubo = lambda x: x*x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cubo(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de datos en python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen datos de tipo **númericos** (Enteros, flotantes, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_1 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una **cadena** es una secuencia de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_2 = \"John Smith\"\n",
    "variable_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una **lista** es un conjunto ordenado de elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_3 = [10, \"John Smith\", ['another', 'list']]\n",
    "variable_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_3[2] = \"Adolfo\"\n",
    "variable_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una **tupla** es una lista inmutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_4 = (10, \"John Smith\")\n",
    "variable_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **diccionario** contiene pares llave-valor (KV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_5 = {\"name\": \"John Smith\", \"age\": 45}\n",
    "variable_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_5['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de uso de bibliotecas de sistema operativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir(\"data/data_berka/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede obtener lo mismo con comandos _mágicos_ de `Jupyter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls data/data_berka/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark \n",
    "\n",
    "_A fast and general engine for large scale data processing _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- _Framework_ de cómputo general para _clusters_\n",
    "- Ejecuta en `YARN`\n",
    "  - Aunque también puede hacer _standalone_, o ejecutar sobre `EC2` o `Mesos`.\n",
    "- Soporta varios lenguajes\n",
    "  - `Python`, `Java`,  `Scala` y recientemente en `R`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Spark-2015-Vision.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Por qué Apache Spark?\n",
    "\n",
    "\n",
    "* Algoritmos iterativos\n",
    "* Exploración interactiva\n",
    "* Plataforma unificada de análisis de datos (en gran escala)\n",
    "    - _batch_, interactivo, _streaming_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historia de Spark\n",
    "\n",
    "- `Mesos`, era un _framework_ distribuido creado como proyecto para una clase en UC Berkeley in 2009. \n",
    "- `Spark` fué creado para ver si `Mesos` funcionaba.\n",
    "- Fué abierto a partir de 2010 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resilient Distributed Datasets (RDDs)\n",
    "\n",
    "- Es una de las ideas principales de Spark.\n",
    "- `RDDs` es una abstracción que representa una colleción de objetos de sólo lectura que está particionada a lo largo de varias máquinas.\n",
    "- Sus ventajas:\n",
    "  - Pueden ser reconstruidas a partir de su _lineage_. (Soportan fallos...)\n",
    "  - Pueden ser accesadas vía operaciones en paralelo, parecidas a MapReduce.\n",
    "  - Son _cached_ en memoria para su uso inmediato.\n",
    "  - Fueron construidas para ser almacenadas de manera distribuida.\n",
    "  - Contienen cualquier tipo de dato (ya sea de `Python`, `R`, `Java` o `Scala`) incluidos tipos definidos por el programador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Soportan dos tipos de operaciones\n",
    "  - *Transformaciones*\n",
    "  - *Acciones*.\n",
    "\n",
    "- Las _transformaciones_ construyen un `RDD` nuevo a partir del anterior.\n",
    "  - Cada transformación queda guardada por =Spark= en el /lineage graph/ un *DAG*.\n",
    "\n",
    "- Las _acciones_ calculan un resultado basado en el `RDD`.\n",
    "\n",
    "- La diferencia es que las `RDD` son computadas en forma _lazy_, sólo son ejecutadas hasta la acción.\n",
    "\n",
    "- Si quieres usarlo una `RDD` varias veces debes de persistirla (con `persist()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flujo típico de trabajo\n",
    "\n",
    "1. Crear un `RDD` a partir de datos externos.\n",
    "2. Transformarlo a nuevos `RDDs`.\n",
    "3. Persistir algunos `RDDs` para su uso posterior.\n",
    "4. Lanzar acciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de flujo de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts = sc.textFile(\"data/data_berka/account.asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_poplatek = accounts.filter(lambda account: \"POPLATEK\" not in account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_poplatek.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_poplatek.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def notPopLatek(account):\n",
    "    return \"POPLATEK\" not in account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_poplatek = accounts.filter(notPopLatek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_poplatek.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_poplatek.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark - RDD API\n",
    "\n",
    "* [RDD API](http://spark.apache.org/docs/1.3.0/api/scala/index.html#org.apache.spark.rdd.RDD)\n",
    "\n",
    "* From API docs: \"immutable, partitioned collection of elements that can be operated on in parallel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - `map`\n",
    "    - Usa una función y la aplica a cada elemento del `RDD`, el resultado se guarda en un nuevo `RDD`.\n",
    "  - `filter`\n",
    "    - Usa una función y devuelve sólo los elementos que pasan la función (que devuelven verdadero) en el nuevo `RDD`.\n",
    "  - `flatMap`\n",
    "    - Como el `map` pero regresa un iterador por cada elemento\n",
    "      - Por ejemplo una función que divide una cadena.\n",
    "  - `distinct`, `sample`\n",
    "  - `union`, `intersection`, `substract`, `cartesian`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeros = sc.parallelize([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeros.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuadrados = numeros.map(lambda x: x*x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cuadrado in cuadrados:\n",
    "    print(\"%i \" % (cuadrado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pares = numeros.filter(lambda x: x%2 == 0).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for par in pares:\n",
    "    print(\"%i \" % (par))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frases = sc.parallelize([\"hola estudiantes\", \"xvii congreso estudiantil\"])\n",
    "palabras = frases.flatMap(lambda frase: frase.split(\" \"))\n",
    "palabras.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `reduce`\n",
    "  - Opera en dos elementos del mismo tipo del `RDD` y regresa un elemento del mismo tipo.\n",
    "- `aggregate`\n",
    "  - Nos permite implementar acumuladores.\n",
    "- `collect`\n",
    "  - Regresa el `RDD` completo.\n",
    "- =`ake`\n",
    "  - Regresa un número =n= de elementos del  =RDD=.\n",
    "- `count`, `countByValue`, `top`, `foreach`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "suma = numeros.reduce(lambda x, y: x + y)\n",
    "suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumaConteo = numeros.aggregate((0, 0), # Valor inicial\n",
    "                               (lambda acc, value: (acc[0] + value, acc[1] + 1)), # Combinamos el RDD con el acumulador\n",
    "                               (lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])) # Juntamos ambos acumuladores\n",
    "                              ) \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumaConteo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumaConteo[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumaConteo[0]/float(sumaConteo[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeros.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeros.top(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeros.takeSample(withReplacement=True, num=2, seed=1334 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts_csv = accounts.\\\n",
    "            filter(lambda line: \"account_id\" not in line).\\\n",
    "            map(lambda x: x.split(\";\"))\n",
    "accounts_csv.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kv_accounts = accounts_csv.map(lambda x: (x[1], x)) # x[1] contiene el district_id\n",
    "kv_accounts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kv_accounts.keys().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kv_accounts.values().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kv_accounts.sortByKey().take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kv_districts = sc.textFile(\"data/data_berka/district.asc\").\\\n",
    "                filter(lambda x: \"A1\" not in x).\\\n",
    "                map(lambda x: x.split(\";\")).\\\n",
    "                map(lambda x: (x[0], x))\n",
    "kv_districts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts_district = kv_accounts.join(kv_districts)\n",
    "accounts_district.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer y escribir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivos de texto\n",
    "\n",
    "Un registro, una línea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients = sc.textFile(\"data/data_berka/client.asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clients.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clients.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_clients = clients.sample(withReplacement=False, fraction=0.01, seed=1334)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -R output/sampled_clients/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_clients.saveAsTextFile(\"output/sampled_clients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accounts_df = sqlContext.read.format('com.databricks.spark.csv').\\\n",
    "                options(header='true', delimiter=';').\\\n",
    "                load(\"data/data_berka/account.asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -R output/accounts_csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts_df.select(\"account_id\", \"district_id\", \"frequency\").\\\n",
    "            write.format(\"com.databricks.spark.csv\").\\\n",
    "            save(\"output/accounts_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SparkSQL` además de permitirnos interactuar usando `SQL` con los `RDDs` (en realidad `HQL` _Hive query language_, ver documentación [aquí](https://cwiki.apache.org/confluence/display/Hive/LanguageManual)), agregar una capa de abstracción al `RDD` y lo convierte en un `DataFrame` análogo al usado en `R` y `Python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accounts_df.registerTempTable('accounts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlCtx.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlCtx.sql('select * from accounts limit 5').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL y archivos JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `sparkSQL` es más fácil tratar con archivos `json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -R data/world_bank*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! wget http://jsonstudio.com/wp-content/uploads/2014/02/world_bank.zip -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! unzip data/world_bank.zip -d data/world_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "world_bank = sqlCtx.read.json(\"data/world_bank/world_bank.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Automáticamente detecta el _esquema_ de la fuente de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_bank.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "world_bank.registerTempTable(\"world_bank_projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlCtx.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlCtx.sql('select countryshortname, project_name, totalamt, totalcommamt from world_bank_projects order by countryshortname').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country = sqlCtx.sql('select countryshortname as country, count(project_name) as num_projects, sum(totalamt) as total_amount from world_bank_projects group by countryshortname order by countryshortname')\n",
    "projects_by_country.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL y Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible usar `Pandas` para hacer análisis, pero hay que tomar en cuenta que esto manda _todo_ el `dataset` a un sólo nodo (más adelante veremos como usar `MLib` para hacerlo de manera distribuida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd = projects_by_country.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd=projects_by_country_pd.set_index(['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd.num_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_by_country_pd.ix['Peru']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "projects_by_country_pd['num_projects'][:10].plot(kind='barh', rot=0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo básico: WordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargaremos del [Proyecto Gutenberg](https://www.gutenberg.org) el libro [Beowulf](https://www.gutenberg.org/ebooks/16328) de J. Lesslie Hall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! wget https://www.gutenberg.org/ebooks/16328.txt.utf-8 -P data/books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(texto):\n",
    "    return texto.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veámos que hace esta función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenize(\"En el bosque, de la China, la chinita se perdió\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beowulf = sc.textFile(\"data/books/16328.txt.utf-8\") # Creamos el RDD desde archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcount = beowulf.map(lambda line: line.lower()).\\\n",
    "                        flatMap(tokenize).\\\n",
    "                        map(lambda x: (x,1)).\\\n",
    "                        reduceByKey(lambda x, y: x + y).\\\n",
    "                        map(lambda x: (x[1], x[0])).\\\n",
    "                        sortByKey(ascending=False)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcount.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, hay muchas palabras que no dicen nada sobre la obra, para hacer _minería de textos_ tendríamos que limpiarlas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veámoslo en `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_counted = pd.DataFrame(wordcount.collect(), columns=[\"freq\", \"word\"])\n",
    "words_counted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_counted['freq'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,12));\n",
    "words_counted['freq'][:100].plot(kind=\"bar\")\n",
    "ax.set_xticklabels(words_counted['word'][:100]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
